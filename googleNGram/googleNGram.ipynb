{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "% matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "see https://en.wikipedia.org/wiki/WordNet for details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['love',\n",
       " 'passion',\n",
       " 'beloved',\n",
       " 'dear',\n",
       " 'dearest',\n",
       " 'honey',\n",
       " 'sexual_love',\n",
       " 'erotic_love',\n",
       " 'lovemaking',\n",
       " 'making_love',\n",
       " 'love_life',\n",
       " 'enjoy',\n",
       " 'sleep_together',\n",
       " 'roll_in_the_hay',\n",
       " 'make_out',\n",
       " 'make_love',\n",
       " 'sleep_with',\n",
       " 'get_laid',\n",
       " 'have_sex',\n",
       " 'know',\n",
       " 'do_it',\n",
       " 'be_intimate',\n",
       " 'have_intercourse',\n",
       " 'have_it_away',\n",
       " 'have_it_off',\n",
       " 'screw',\n",
       " 'fuck',\n",
       " 'jazz',\n",
       " 'eff',\n",
       " 'hump',\n",
       " 'lie_with',\n",
       " 'bed',\n",
       " 'have_a_go_at_it',\n",
       " 'bang',\n",
       " 'get_it_on',\n",
       " 'bonk']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import wordnet as wn\n",
    "\n",
    "targetWord = 'love'\n",
    "syns = wn.synsets(targetWord)\n",
    "wordCloud = []\n",
    "wordCloudSim = []\n",
    "for word in syns:\n",
    "    for lemma in word.lemmas():\n",
    "        if lemma.name() not in wordCloud:\n",
    "            wordCloud.append(str(lemma.name()))\n",
    "            \n",
    "wordCloud"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the problem with this is that, this list only contains 'lemmas' and not various forms of the words (loved, lover, loving, ...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Synset('sleep_together.v.01')]\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print wn.synsets('do_it')\n",
    "print wn.synset('love.n.01').wup_similarity(wn.synset('do_it.v.01'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os.path\n",
    "import urllib\n",
    "import pandas as pd\n",
    "\n",
    "columns = ['ngram', 'year', 'match_count', 'volume_count']\n",
    "dataf = pd.DataFrame(columns=columns)\n",
    "for word in wordCloud:\n",
    "    wordsp = word.split('_')\n",
    "    n = len(wordsp)\n",
    "    indices = ''.join([x[0] for x in wordsp][:2])\n",
    "    filename = 'googlebooks-eng-all-{}gram-20120701-{}.gz'.format(n, indices)\n",
    "    if not os.path.isfile(filename):\n",
    "        urllib.urlretrieve (\"http://storage.googleapis.com/books/ngrams/books/\"+filename, filename)\n",
    "    else:\n",
    "        data = pd.read_table(filename, sep='\\t', header=None, names=columns)\n",
    "        dataf.append(data[data.ngram == word])\n",
    "dataf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
